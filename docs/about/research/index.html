<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="Nestor Demeure ">
<meta name="description" content="I am a researcher with specialties in numerical accuracy, artificial intelligence, data analysis, and high-performance computing.
Papers   You can find most of my publications on Researchgate:
High-level GPU code: a case study examining JAX and OpenMP. (high-performance computing)   This paper (published as part of the proceedings of Supercomputing 2023) contrasts and compares the use of both JAX and OpenMP target offload to port a large cosmology code to GPU." />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://nestordemeure.github.io/about/research/" />


    <title>
        
            Research I did :: Nestor Demeure 
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">



<link rel="stylesheet" href="https://nestordemeure.github.io/main.4e5c639214707eff609bb55fe49e183dee42258a73bc90e4cc7b0a84f900798a.css">


    
        <link rel="stylesheet" type="text/css" href="https://nestordemeure.github.io/css/style.css">
    


    <link rel="apple-touch-icon" sizes="180x180" href="https://nestordemeure.github.io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://nestordemeure.github.io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://nestordemeure.github.io/favicon-16x16.png">
    <link rel="manifest" href="https://nestordemeure.github.io/site.webmanifest">
    <link rel="mask-icon" href="https://nestordemeure.github.io/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="https://nestordemeure.github.io/favicon.ico">
    <meta name="msapplication-TileColor" content="">


<meta itemprop="name" content="Research I did">
<meta itemprop="description" content="I am a researcher with specialties in numerical accuracy, artificial intelligence, data analysis, and high-performance computing.
Papers   You can find most of my publications on Researchgate:
High-level GPU code: a case study examining JAX and OpenMP. (high-performance computing)   This paper (published as part of the proceedings of Supercomputing 2023) contrasts and compares the use of both JAX and OpenMP target offload to port a large cosmology code to GPU.">
<meta itemprop="dateModified" content="2024-03-18T11:49:10-07:00" />
<meta itemprop="wordCount" content="1303"><meta itemprop="image" content="https://nestordemeure.github.io/"/>
<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://nestordemeure.github.io/"/>

<meta name="twitter:title" content="Research I did"/>
<meta name="twitter:description" content="I am a researcher with specialties in numerical accuracy, artificial intelligence, data analysis, and high-performance computing.
Papers   You can find most of my publications on Researchgate:
High-level GPU code: a case study examining JAX and OpenMP. (high-performance computing)   This paper (published as part of the proceedings of Supercomputing 2023) contrasts and compares the use of both JAX and OpenMP target offload to port a large cosmology code to GPU."/>




    <meta property="og:title" content="Research I did" />
<meta property="og:description" content="I am a researcher with specialties in numerical accuracy, artificial intelligence, data analysis, and high-performance computing.
Papers   You can find most of my publications on Researchgate:
High-level GPU code: a case study examining JAX and OpenMP. (high-performance computing)   This paper (published as part of the proceedings of Supercomputing 2023) contrasts and compares the use of both JAX and OpenMP target offload to port a large cosmology code to GPU." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://nestordemeure.github.io/about/research/" /><meta property="og:image" content="https://nestordemeure.github.io/"/><meta property="article:section" content="about" />

<meta property="article:modified_time" content="2024-03-18T11:49:10-07:00" /><meta property="og:site_name" content="Nestor Demeure" />
















    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://nestordemeure.github.io/posts" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">&gt;</span>
            <span class="logo__text">$ cd /home/nestor/</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://nestordemeure.github.io/about">About</a></li><li><a href="https://nestordemeure.github.io/cooking">Cooking</a></li><li><a href="https://nestordemeure.github.io/likes">Likes</a></li><li><a href="https://nestordemeure.github.io/writing">Writing</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            
        </span>
    </span>
</header>


            <div class="content">
                
    <main class="post">

        <div class="post-info">
            
            </p>
        </div>

        <article>
            <h2 class="post-title"><a href="https://nestordemeure.github.io/about/research/">Research I did</a></h2>

            
            
            

            <div class="post-content">
                <p>I am a researcher with specialties in numerical accuracy, artificial intelligence, data analysis, and high-performance computing.</p>
<div class="heading-wrapper">
    <h2 id="papers">
        <a class="heading-anchor" href="#papers" style="text-decoration: none">
            Papers
        </a>
    </h2>
</div><p>You can find most of my publications on <a href="https://www.researchgate.net/profile/Nestor-Demeure">Researchgate</a>:</p>
<div class="heading-wrapper">
    <h4 id="high-level-gpu-code-a-case-study-examining-jax-and-openmphttpsdlacmorgdoi10114536240623624186-high-performance-computing">
        <a class="heading-anchor" href="#high-level-gpu-code-a-case-study-examining-jax-and-openmphttpsdlacmorgdoi10114536240623624186-high-performance-computing" style="text-decoration: none">
            <a href="https://dl.acm.org/doi/10.1145/3624062.3624186">High-level GPU code: a case study examining JAX and OpenMP.</a> (high-performance computing)
        </a>
    </h4>
</div><p>This paper (published as part of the proceedings of <em>Supercomputing 2023</em>) contrasts and compares the use of both JAX and OpenMP target offload to port a large cosmology code to GPU.</p>
<p>It gives a practical look at porting a large pre-existing application to GPU, studying the performance of the resulting code but also usability and productivity.</p>
<div class="heading-wrapper">
    <h4 id="porting-a-large-cosmology-code-to-gpu-a-case-study-examining-jax-and-openmphttpscugorgproceedingscug2023_proceedingsat_a_glancehtml-high-performance-computing">
        <a class="heading-anchor" href="#porting-a-large-cosmology-code-to-gpu-a-case-study-examining-jax-and-openmphttpscugorgproceedingscug2023_proceedingsat_a_glancehtml-high-performance-computing" style="text-decoration: none">
            <a href="https://cug.org/proceedings/cug2023_proceedings/at_a_glance.html">Porting a large cosmology code to GPU, a case study examining JAX and OpenMP.</a> (high-performance computing)
        </a>
    </h4>
</div><p>This paper (published as part of the proceedings of the <em>Cray User Group 2023</em>) contrasts and compares the use of both JAX and OpenMP target offload to port a large cosmology code to GPU.</p>
<p>It gives a practical look at porting a large pre-existing application to GPU, studying the performance of the resulting code but also usability and productivity.</p>
<div class="heading-wrapper">
    <h4 id="encapsulated-error-a-direct-approach-to-evaluate-floating-point-accuracyhttpsdlacmorgdoi1011453549205-numerical-accuracy">
        <a class="heading-anchor" href="#encapsulated-error-a-direct-approach-to-evaluate-floating-point-accuracyhttpsdlacmorgdoi1011453549205-numerical-accuracy" style="text-decoration: none">
            <a href="https://dl.acm.org/doi/10.1145/3549205">Encapsulated error, a direct approach to evaluate floating-point accuracy</a> (numerical accuracy)
        </a>
    </h4>
</div><p>This paper covers my work on <em>encapsulated error</em>, a method designed to measure the numerical error of computations while being efficient enough to be applied to large parallel applications running on a supercomputer.</p>
<p>The method is interesting in that it is both relatively easy to implement as a library, accurate, and significantly faster than most alternatives.
Its main downside is the need to replace floating-point types used in an application with an instrumented alternative (which might not be practical when one has limited access to the source or when they are unwieldy to modify).</p>
<div class="heading-wrapper">
    <h4 id="ranger21-a-synergistic-deep-learning-optimizerhttpsarxivorgabs210613731-machine-learning">
        <a class="heading-anchor" href="#ranger21-a-synergistic-deep-learning-optimizerhttpsarxivorgabs210613731-machine-learning" style="text-decoration: none">
            <a href="https://arxiv.org/abs/2106.13731">Ranger21: a synergistic deep learning optimizer</a> (machine learning)
        </a>
    </h4>
</div><p>The Ranger21 paper was born from testing a large number of optimizers for deep learning and realizing that, while people were branding them as new optimizers, they often just included one new idea to an existing optimizer.
We realized a lot of those ideas were orthogonal and synergistic: you would get better results putting them together than what would be expected by looking at them individually.</p>
<p>The result is an optimizer that is surprisingly robust and, looking further, the idea that we should build modular optimizers to foster research in that direction.</p>
<div class="heading-wrapper">
    <h4 id="tagged-error-tracing-numerical-error-through-computationshttpsieeexploreieeeorgdocument9603395-numerical-accuracy">
        <a class="heading-anchor" href="#tagged-error-tracing-numerical-error-through-computationshttpsieeexploreieeeorgdocument9603395-numerical-accuracy" style="text-decoration: none">
            <a href="https://ieeexplore.ieee.org/document/9603395">Tagged error: tracing numerical error through computations</a> (numerical accuracy)
        </a>
    </h4>
</div><p>This paper covers my work on <em>tagged error</em>, an extension of <em>encapsulated error</em> designed to follow numerical error through a computation.</p>
<p>While the method introduces an important overhead, it is the best method I am aware of to find the source of a numerical error in computations.
I have even used it to improve the numerical stability of algorithms, fixing problems one after the other until I reached the desired precision.</p>
<div class="heading-wrapper">
    <h4 id="compromise-between-precision-and-performance-in-high-performance-computinghttpswwwresearchgatenetpublication348551075_compromise_between_precision_and_performance_in_high_performance_computing-numerical-accuracy">
        <a class="heading-anchor" href="#compromise-between-precision-and-performance-in-high-performance-computinghttpswwwresearchgatenetpublication348551075_compromise_between_precision_and_performance_in_high_performance_computing-numerical-accuracy" style="text-decoration: none">
            <a href="https://www.researchgate.net/publication/348551075_Compromise_between_precision_and_performance_in_high_performance_computing">Compromise between precision and performance in high-performance computing.</a> (numerical accuracy)
        </a>
    </h4>
</div><p>This covers all the work I did during my Ph.D. (do not let the first pages fool you, it is written in English).</p>
<p>It covers the theory behind Shaman including <em>encapsulated error</em> (a very efficient way to measure the numerical error of computations) and <em>tagged error</em> (a very precise way to find the source of the numerical error that ends up in a result).</p>
<p>It also includes some work on applying artificial intelligence to pick the proper solver and preconditioner to solve a linear system (we obtained really promising results, a paper dedicated to the subject should come out at some point).</p>
<div class="heading-wrapper">
    <h4 id="large-scale-neuroanatomical-study-uncovers-198-gene-associations-in-mouse-brain-morphogenesishttpswwwnaturecomarticless41467-019-11431-2-data-analysis">
        <a class="heading-anchor" href="#large-scale-neuroanatomical-study-uncovers-198-gene-associations-in-mouse-brain-morphogenesishttpswwwnaturecomarticless41467-019-11431-2-data-analysis" style="text-decoration: none">
            <a href="https://www.nature.com/articles/s41467-019-11431-2">Large-scale neuroanatomical study uncovers 198 gene associations in mouse brain morphogenesis</a> (data analysis)
        </a>
    </h4>
</div><p>This paper concludes a large study, measuring 118 neuroanatomical parameters over 1,566 mutant mice.
This leads to the identification of 198 genes that impact brain formation.</p>
<p>I contributed some data analysis to the paper (admittedly a drop in the bucket, with 18 co-authors contributing much more important pieces of the puzzle).</p>
<div class="heading-wrapper">
    <h2 id="talks">
        <a class="heading-anchor" href="#talks" style="text-decoration: none">
            Talks
        </a>
    </h2>
</div><p>Here are slides (or recordings when available) of talks I gave:</p>
<div class="heading-wrapper">
    <h4 id="intelligence-artificielle--opportunités-risques-et-défishttpsdocsgooglecompresentationd1sb0djb66khxq-18t6-8ngtftr5hukh8t6rvvdbwivpsedituspsharing-machine-learning">
        <a class="heading-anchor" href="#intelligence-artificielle--opportunit%c3%a9s-risques-et-d%c3%a9fishttpsdocsgooglecompresentationd1sb0djb66khxq-18t6-8ngtftr5hukh8t6rvvdbwivpsedituspsharing-machine-learning" style="text-decoration: none">
            <a href="https://docs.google.com/presentation/d/1sB0Djb66kHxQ-18t6-8NgTFtR5HUKh8T6rvvdbwIVps/edit?usp=sharing">Intelligence Artificielle : Opportunités, Risques et Défis</a> (machine learning)
        </a>
    </h4>
</div><p>This talk was given at the French <em>École Supérieure Arts Appliqués Textile</em> (School of Higher Studies in Applied Arts and Textiles), an art school specializing in design and textiles, in April 2024.
The goal was to provide an overview of how modern generative AI works, what it can and cannot currently do, current legislation, as well as societal impacts of these techniques. With an emphasis on what we know, don&rsquo;t know, and cannot yet know as techniques are rapidly evolving.
An audio recording of the talk and subsequent discussion can be found on <a href="https://audioblog.arteradio.com/blog/201201/podcast/226908/intelligence-artificielle-conference-interactive">RADAR</a>, the school&rsquo;s radio station.</p>
<div class="heading-wrapper">
    <h4 id="high-level-gpu-code-a-case-study-examining-jax-and-openmphttpsdocsgooglecompresentationd1jqwamre9_-iiwpqslpxs7cw-svqxv5xpgdwbd12l0ioedituspsharing-high-performance-computing">
        <a class="heading-anchor" href="#high-level-gpu-code-a-case-study-examining-jax-and-openmphttpsdocsgooglecompresentationd1jqwamre9_-iiwpqslpxs7cw-svqxv5xpgdwbd12l0ioedituspsharing-high-performance-computing" style="text-decoration: none">
            <a href="https://docs.google.com/presentation/d/1JQwaMre9_-iiwPqslPXS7CW-SvQxv5XPgdWBd12L0io/edit?usp=sharing">High-level GPU code: A case study examining JAX and OpenMP.</a> (high-performance computing)
        </a>
    </h4>
</div><p>This talk was given at <em>P3HPC</em> (Performance, Portability &amp; Productivity in HPC, a workshop given as part of <em>Supercomputing 2023</em>) and the <em>Summit Series XIII</em> (an NVIDIA and US national labs joined conference).
It contrasts and compares the use of both JAX and OpenMP target offload to port a large cosmology code to GPU, looking at the performance of the resulting code but also usability and productivity.</p>
<p>A paper is also available in the <a href="https://dl.acm.org/doi/10.1145/3624062.3624186">proceedings of the conference</a>.</p>
<div class="heading-wrapper">
    <h4 id="porting-a-large-cosmology-code-to-gpu-a-case-study-examining-jax-and-openmphttpsdocsgooglecompresentationd1evrpdsujyp2zqg05tyhspafvj0ajrzpzs0_lnd2ivk8edituspsharing-high-performance-computing">
        <a class="heading-anchor" href="#porting-a-large-cosmology-code-to-gpu-a-case-study-examining-jax-and-openmphttpsdocsgooglecompresentationd1evrpdsujyp2zqg05tyhspafvj0ajrzpzs0_lnd2ivk8edituspsharing-high-performance-computing" style="text-decoration: none">
            <a href="https://docs.google.com/presentation/d/1eVrpDsUJYp2ZqG05TYHSpAfvJ0AJRZPzS0_lND2ivk8/edit?usp=sharing">Porting a large cosmology code to GPU, a case study examining JAX and OpenMP.</a> (high-performance computing)
        </a>
    </h4>
</div><p>This talk, given at the <em>Cray User Group 2023</em>, contrasts and compares the use of both JAX and OpenMP target offload to port a large cosmology code to GPU, looking at the performance of the resulting code but also usability and productivity.</p>
<p>A paper is also available in the <a href="https://cug.org/digital-library/">proceedings of the conference</a>.</p>
<div class="heading-wrapper">
    <h4 id="workshop-introduction-to-porting-python-to-gpu-with-jaxhttpsyoutubeyhxuymsq_3glistpl20s5eeapostvfx3byeoje-z93d64xale-high-performance-computing">
        <a class="heading-anchor" href="#workshop-introduction-to-porting-python-to-gpu-with-jaxhttpsyoutubeyhxuymsq_3glistpl20s5eeapostvfx3byeoje-z93d64xale-high-performance-computing" style="text-decoration: none">
            <a href="https://youtu.be/YhXUymsQ_3g?list=PL20S5EeApOStvfX3byEoJe-Z93D64xaLE">Workshop: Introduction to porting Python to GPU with JAX.</a> (high-performance computing)
        </a>
    </h4>
</div><p>This workshop (given in 2022 for the <em>Commonwealth Computational Summit 2022</em> and later at the <em>Data Day 2022</em> and <em>NUG Meeting 2022</em>) is an introduction to porting Python code, and in particular numerical and scientific applications, to GPU with <a href="https://github.com/google/jax">JAX</a>.</p>
<p>It comes with <a href="https://drive.google.com/drive/folders/12SO8IwMv2CP6vRmtgWwJ9Xekw8a2B-aT?usp=sharing">exercises</a> and is designed such that, by the end of the workshop, someone starting with knowledge of Python and Numpy should be able to port their code to GPU using JAX <em>and</em> decide on whether it is the best way forward.</p>
<div class="heading-wrapper">
    <h4 id="tagged-error-tracing-numerical-error-through-computationshttpsdrivegooglecomfiled1mt-qcboqcdd36-6dwi4ee6gwhiox_hgfviewuspsharing-numerical-accuracy">
        <a class="heading-anchor" href="#tagged-error-tracing-numerical-error-through-computationshttpsdrivegooglecomfiled1mt-qcboqcdd36-6dwi4ee6gwhiox_hgfviewuspsharing-numerical-accuracy" style="text-decoration: none">
            <a href="https://drive.google.com/file/d/1mt-QCBOqcdD36-6DwI4eE6GwHIoX_hGf/view?usp=sharing">Tagged error: Tracing numerical error through computations.</a> (numerical accuracy)
        </a>
    </h4>
</div><p>This talk (given in 2021 for the <em>28th IEEE International Symposium on Computer Arithmetic.</em>) covers my work on <em>tagged error</em>, an extension of <em>encapsulated error</em> designed to follow numerical error through a computation.</p>
<p>It has since been published as a <a href="https://ieeexplore.ieee.org/document/9603395">paper</a>.</p>
<div class="heading-wrapper">
    <h4 id="erreur-encapsulée-une-méthode-directe-pour-estimer-lerreur-due-à-larithmétique-à-virgule-flottantehttpsdrivegooglecomfiled1us7toi0t45vulcmwryxalyfezkznejojviewuspsharing-numerical-accuracy">
        <a class="heading-anchor" href="#erreur-encapsul%c3%a9e-une-m%c3%a9thode-directe-pour-estimer-lerreur-due-%c3%a0-larithm%c3%a9tique-%c3%a0-virgule-flottantehttpsdrivegooglecomfiled1us7toi0t45vulcmwryxalyfezkznejojviewuspsharing-numerical-accuracy" style="text-decoration: none">
            <a href="https://drive.google.com/file/d/1US7Toi0T45VulCMWRyxALYfezKznEjOJ/view?usp=sharing">Erreur Encapsulée: Une méthode directe pour estimer l’erreur due à l’arithmétique à virgule flottante</a> (numerical accuracy)
        </a>
    </h4>
</div><p>This talk (given in 2021 for the <em>Rencontres Arithmétiques de l&rsquo;Informatique Mathématique 2021</em>) covers my work on <em>encapsulated error</em>, a method designed to measure the numerical error of computations while being efficient enough to be applied to large parallel applications running on a supercomputer.</p>
<p>It has since been published as a <a href="https://ieeexplore.ieee.org/document/9603395">paper</a>.</p>
<div class="heading-wrapper">
    <h4 id="ai-augmented-linear-solvers-using-machine-learning-to-predict-the-convergence-profile-of-a-linear-solverhttpsyoutubekxwpjapwlz0listplr1vc4zveozn3dczlixjd_olg9mplev1b-machine-learning">
        <a class="heading-anchor" href="#ai-augmented-linear-solvers-using-machine-learning-to-predict-the-convergence-profile-of-a-linear-solverhttpsyoutubekxwpjapwlz0listplr1vc4zveozn3dczlixjd_olg9mplev1b-machine-learning" style="text-decoration: none">
            <a href="https://youtu.be/kXwPJAPwLz0?list=PLr1vc4ZveozN3DCzlIxJd_oLG9MpLev1B">AI-augmented linear solvers: using machine learning to predict the convergence profile of a linear solver</a> (machine learning)
        </a>
    </h4>
</div><p>This talk (given in 2020 for the <em>Digital French-German Summer School with Industry</em>) covers my work on using machine learning to predict the performance of linear solvers and preconditioners when solving a given linear system.</p>
<p>We showed that we could predict the convergence profile of the solver with enough accuracy to determine which solver should be used given some target precision and time constraints.</p>
<p>You can find further information <a href="https://www.researchgate.net/publication/348551075_Compromise_between_precision_and_performance_in_high_performance_computing">in my Ph.D.</a></p>
<div class="heading-wrapper">
    <h2 id="posters">
        <a class="heading-anchor" href="#posters" style="text-decoration: none">
            Posters
        </a>
    </h2>
</div><p>Here are posters I presented:</p>
<div class="heading-wrapper">
    <h4 id="a-direct-method-to-assess-floating-point-accuracyhttpsdrivegooglecomfiled1gnm7fkpzk9yupydiceoiglmve9fjbplpviewuspsharing-numerical-accuracy">
        <a class="heading-anchor" href="#a-direct-method-to-assess-floating-point-accuracyhttpsdrivegooglecomfiled1gnm7fkpzk9yupydiceoiglmve9fjbplpviewuspsharing-numerical-accuracy" style="text-decoration: none">
            <a href="https://drive.google.com/file/d/1GNm7FKPzk9YUpYDiCeoIgLMvE9FJbPlP/view?usp=sharing">A Direct Method to Assess Floating-Point Accuracy</a> (numerical accuracy)
        </a>
    </h4>
</div><p>This poster (presented in 2021 at the <em>Platform for Advanced Scientific Computing (PASC)</em> Conference) covers my work on measuring numerical error and tracing it through computations.</p>
<div class="heading-wrapper">
    <h4 id="uncertainty-quantification-and-numerical-accuracyhttpsdrivegooglecomfiled1vrqqrqgu2rdpcv2jdebussbqj7hwe-pmviewuspsharing-numerical-accuracy">
        <a class="heading-anchor" href="#uncertainty-quantification-and-numerical-accuracyhttpsdrivegooglecomfiled1vrqqrqgu2rdpcv2jdebussbqj7hwe-pmviewuspsharing-numerical-accuracy" style="text-decoration: none">
            <a href="https://drive.google.com/file/d/1VrqqRQgU2RDPcv2JdEbuSsbQj7hWE-pM/view?usp=sharing">Uncertainty Quantification and Numerical Accuracy</a> (numerical accuracy)
        </a>
    </h4>
</div><p>This poster (presented in 2020 at <em>MASCOT-NUM</em>) covers some of my work on measuring numerical error and its application in comparing various uncertainty quantification methods and measuring their sensitivity to numerical error in their inputs.</p>
<p>This particular case study is further detailed <a href="https://www.researchgate.net/publication/348551075_Compromise_between_precision_and_performance_in_high_performance_computing">in my Ph.D.</a></p>

            </div>
        </article>

        <hr />

        <div class="post-info">
            
            
			    <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-git-commit"><circle cx="12" cy="12" r="4"></circle><line x1="1.05" y1="12" x2="7" y2="12"></line><line x1="17.01" y1="12" x2="22.96" y2="12"></line></svg><a href="909f2f85155213a081a816b9215786198124f4a2" target="_blank" rel="noopener">909f2f8</a> @ 2024-03-18</p>
  		</div>
    </main>

            </div>

            
                <footer class="footer">
    
    
</footer>

            
        </div>

        



<script type="text/javascript" src="https://nestordemeure.github.io/bundle.min.a2c5b062c87998f04d1b5dfb6a89a1b2d79786c21d0cb63a05e8a2082984b64b77d80955e3b97eab17273775162ba372511b711fea2f7608f216e68a67bb22d6.js" integrity="sha512-osWwYsh5mPBNG137aomhsteXhsIdDLY6BeiiCCmEtkt32AlV47l&#43;qxcnN3UWK6NyURtxH&#43;ovdgjyFuaKZ7si1g=="></script>


    
        <script src="https://nestordemeure.github.io/js/sidenote.js"></script>
    

    
        <script src="https://nestordemeure.github.io/js/main.js"></script>
    


    </body>
</html>
